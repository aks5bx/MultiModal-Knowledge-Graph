{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import hydra\n",
    "from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel\n",
    "import dgl\n",
    "\n",
    "# from omegaconf import DictConfig, OmegaConf\n",
    "from src.datamodules.mscoco import MSCOCODataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf\n",
    "root = \"coco\"\n",
    "partition = \"val2017\"\n",
    "batch_size = 100\n",
    "num_workers = 8\n",
    "\n",
    "vision_model = \"ViT-B/32\"\n",
    "model_id = \"openai/clip-vit-base-patch32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = CLIPTokenizerFast.from_pretrained(model_id)\n",
    "processor = CLIPProcessor.from_pretrained(model_id)\n",
    "model = CLIPModel.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.30s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ds = MSCOCODataset(\n",
    "        root=root,\n",
    "        annFile=os.path.join(root, \"annotations\", f\"instances_{partition}.json\")\n",
    "        #transform=preprocess\n",
    "    )\n",
    "\n",
    "ann_items = ds.coco.loadCats(ds.coco.getCatIds())\n",
    "tags = [item['name'] for item in ann_items]\n",
    "tag_ids = [item['id'] for item in ann_items]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]\n"
     ]
    }
   ],
   "source": [
    "print(tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding image batches: 100%|██████████| 50/50 [01:41<00:00,  2.02s/it]\n",
      "encoding tags: 100%|██████████| 80/80 [00:01<00:00, 45.83it/s]\n"
     ]
    }
   ],
   "source": [
    "images_tensor = None\n",
    "tags_tensor = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(ds.ids), batch_size), desc='encoding image batches'):\n",
    "        batch_ids = ds.ids[i:i+batch_size]\n",
    "        batch_imgs = [Image.open('coco/images/'+ds.coco.loadImgs(id)[0][\"file_name\"]).convert('RGB') for id in batch_ids]\n",
    "        batch = processor(\n",
    "                    text=None,\n",
    "                    images=batch_imgs,\n",
    "                    return_tensors='pt',\n",
    "                    padding=True\n",
    "                )['pixel_values'].to(device)\n",
    "        batch_emb = model.get_image_features(pixel_values=batch)\n",
    "        batch_emb = batch_emb.squeeze(0)\n",
    "        \n",
    "        if images_tensor is None:\n",
    "            images_tensor = batch_emb\n",
    "        else:\n",
    "            images_tensor = torch.cat((images_tensor, batch_emb), dim=0)\n",
    "\n",
    "    for tag in tqdm(tags, desc='encoding tags'):\n",
    "        inputs = tokenizer(tag, return_tensors=\"pt\")\n",
    "        tag_emb = model.get_text_features(**inputs)\n",
    "\n",
    "        if tags_tensor is None:\n",
    "            tags_tensor = tag_emb\n",
    "        else:\n",
    "            tags_tensor = torch.cat((tags_tensor, tag_emb), dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 512])\n",
      "torch.Size([80, 512])\n",
      "tensor([-0.0724, -0.0059, -0.3013,  0.0826,  0.2546, -0.2976,  0.2935,  0.0293,\n",
      "        -0.0527,  0.0108])\n",
      "tensor([ 0.1695,  0.0864,  0.1535,  0.0774,  0.0044, -0.3187, -0.3133, -1.1808,\n",
      "        -0.2216, -0.0016])\n"
     ]
    }
   ],
   "source": [
    "print(images_tensor.shape)\n",
    "print(tags_tensor.shape)\n",
    "print(images_tensor[0][:10])\n",
    "print(tags_tensor[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_embed_row': 0,\n",
       " 'tag_ids': [64, 1, 67, 72, 78, 82, 84, 85, 86, 62],\n",
       " 'tag_embed_rows': [63, 0, 66, 71, 77, 81, 83, 84, 85, 61],\n",
       " 'tag_names': ['microwave',\n",
       "  'tv',\n",
       "  'vase',\n",
       "  'chair',\n",
       "  'potted plant',\n",
       "  'clock',\n",
       "  'dining table',\n",
       "  'book',\n",
       "  'person',\n",
       "  'refrigerator']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_img_text_table()\n",
    "test_key = list(ds.img_text_data.keys())[0]\n",
    "ds.img_text_data[test_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save image / tag embeddings, as well as relational JSON table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything\n",
    "torch.save(images_tensor, 'coco_image_embeddings.pt')\n",
    "torch.save(tags_tensor, 'coco_tag_embeddings.pt')\n",
    "\n",
    "with open(\"img_text_data.json\", \"w\") as outfile:\n",
    "    json.dump(ds.img_text_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 1, 67, 72, 78, 82, 84, 85, 86, 62]\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# Make sure datatypes for img_text_data are intact\n",
    "with open(\"img_text_data.json\", \"r\") as img_text_json:\n",
    "    img_text_data = json.load(img_text_json)\n",
    "\n",
    "test_key = list(img_text_data.keys())[0]\n",
    "test_img = img_text_data[test_key]\n",
    "print(test_img['tag_ids'])\n",
    "print(test_img['tag_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 512])\n",
      "torch.Size([80, 512])\n",
      "tensor([-0.0724, -0.0059, -0.3013,  0.0826,  0.2546, -0.2976,  0.2935,  0.0293,\n",
      "        -0.0527,  0.0108])\n",
      "tensor([ 0.1695,  0.0864,  0.1535,  0.0774,  0.0044, -0.3187, -0.3133, -1.1808,\n",
      "        -0.2216, -0.0016])\n"
     ]
    }
   ],
   "source": [
    "# Check to ensure no data loss between saving and reloading image / text embeddings\n",
    "images_tensor_reloaded = torch.load('coco_image_embeddings.pt', map_location=device)\n",
    "tags_tensor_reloaded = torch.load('coco_tag_embeddings.pt', map_location=device)\n",
    "\n",
    "print(images_tensor_reloaded.shape)\n",
    "print(tags_tensor_reloaded.shape)\n",
    "\n",
    "print(images_tensor_reloaded[0][:10])\n",
    "print(tags_tensor_reloaded[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph from Embeddings using DGL\n",
    "\n",
    "Special Note: To avoid having duplicate node IDs between images and tags, we reserve node IDs 1 - max(tag_ids) for tags (text) and node IDs >= max(tag_ids) + 1 for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 37, 88, 75, 54, 72, 24, 52, 38, 59, 3, 65, 85, 73, 57, 2, 50, 35, 47, 28, 49, 27, 77, 67, 8, 17, 4, 18, 46, 25, 61, 40, 32, 5, 39, 89, 23, 15, 6, 31, 78, 42, 20, 62, 87, 51, 11, 64, 53, 70, 80, 81, 63, 79, 41, 21, 58, 55, 44, 56, 86, 36, 7, 48, 9, 16, 76, 13, 82, 74, 34, 14, 60, 33, 19, 84, 22, 43, 90, 1]\n",
      "[73, 36, 27, 19, 88, 78, 79, 7, 10, 9, 56, 57, 53, 18, 4, 46, 25, 49, 74, 3, 58, 55, 44, 28, 86, 41, 81, 60, 15, 16, 6, 50, 32, 61, 70, 77, 64, 23, 1, 37, 54, 62, 22, 2, 39, 38, 34, 67, 11, 48, 87, 40, 13, 47, 51, 59, 33, 20, 76, 31, 21, 8, 84, 43, 80, 90, 65, 89, 72, 35, 63, 75, 85, 5, 17, 24, 82, 52, 42, 14]\n"
     ]
    }
   ],
   "source": [
    "tests = tag_ids.copy()\n",
    "random.shuffle(tests)\n",
    "print(tests)\n",
    "print(tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>train_mask</th>\n",
       "      <th>val_mask</th>\n",
       "      <th>test_mask</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.07242653518915176, -0.00588227529078722, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.015050115995109081, -0.6406027674674988, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10296262800693512, 0.34772026538848877, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>805</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00568790640681982, -0.02356841042637825, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>857</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.374350905418396, -0.18562030792236328, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id  train_mask  val_mask  test_mask  \\\n",
       "0      220       False     False       True   \n",
       "1      366        True     False      False   \n",
       "2      713        True     False      False   \n",
       "3      805        True     False      False   \n",
       "4      857        True     False      False   \n",
       "\n",
       "                                                feat  \n",
       "0  -0.07242653518915176, -0.00588227529078722, -0...  \n",
       "1  -0.015050115995109081, -0.6406027674674988, -0...  \n",
       "2  0.10296262800693512, 0.34772026538848877, 0.35...  \n",
       "3  0.00568790640681982, -0.02356841042637825, 0.5...  \n",
       "4  -0.374350905418396, -0.18562030792236328, -0.0...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_val_test_ids(node_ids):\n",
    "    random.shuffle(node_ids)\n",
    "    n = len(node_ids)\n",
    "    train_ct, val_ct = [math.floor(n*0.7), math.ceil(n*0.15)]\n",
    "    return [node_ids[0:train_ct], node_ids[train_ct:train_ct+val_ct], node_ids[train_ct+val_ct:]]\n",
    "\n",
    "def split_mask(node_id, split_ids):\n",
    "    return True if node_id in split_ids else False\n",
    "\n",
    "def nodes_table(node_ids, features):\n",
    "    nodes = pd.DataFrame({'node_id': list(node_ids)})\n",
    "    train_ids, val_ids, test_ids = train_val_test_ids(node_ids)\n",
    "    nodes['train_mask'] = nodes['node_id'].apply(lambda x: split_mask(x, train_ids))\n",
    "    nodes['val_mask'] = nodes['node_id'].apply(lambda x: split_mask(x, val_ids))\n",
    "    nodes['test_mask'] = nodes['node_id'].apply(lambda x: split_mask(x, test_ids))\n",
    "    features = [', '.join([str(val) for val in item]) for item in features.tolist()]\n",
    "    nodes['feat'] = features\n",
    "\n",
    "    return nodes\n",
    "\n",
    "img_id_offset = max(tag_ids) + 1\n",
    "img_ids_rand = [int(key) + img_id_offset for key in img_text_data.keys()]\n",
    "tag_ids_rand = tag_ids.copy()\n",
    "\n",
    "img_nodes = nodes_table([int(key) + img_id_offset for key in img_text_data.keys()], images_tensor)\n",
    "tag_nodes = nodes_table(tag_ids, tags_tensor)\n",
    "\n",
    "nodes = pd.concat([img_nodes, tag_nodes])\n",
    "nodes.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>dst_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  src_id dst_id\n",
       "0    220     64\n",
       "0    220      1\n",
       "0    220     67\n",
       "0    220     72\n",
       "0    220     78"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edges_table(img_text_data):\n",
    "    edges = pd.DataFrame(columns=['src_id', 'dst_id'])\n",
    "    for img_id in img_text_data.keys():\n",
    "        for tag in img_text_data[img_id]['tag_ids']:\n",
    "            edges = pd.concat([edges, pd.DataFrame({'src_id': [int(img_id)+img_id_offset], 'dst_id': [int(tag)]})])\n",
    "    return edges\n",
    "\n",
    "edges = edges_table(img_text_data)\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store graph csv files\n",
    "\n",
    "if not os.path.exists('graph_csv'):\n",
    "    os.mkdir('graph_csv')\n",
    "\n",
    "edges.to_csv('graph_csv/coco_edges.csv')\n",
    "nodes.to_csv('graph_csv/coco_nodes.csv')\n",
    "\n",
    "g_metadata = {\n",
    "    'dataset_name': 'coco_val_graph',\n",
    "    'edge_data': [{'file_name': 'coco_edges.csv'}],\n",
    "    'node_data': [{'file_name': 'coco_nodes.csv'}]\n",
    "}\n",
    "\n",
    "with open('graph_csv/meta.yaml', 'w') as file:\n",
    "    yaml.dump(g_metadata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrechen/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset_base.py:298: DGLWarning: Unamed column is found. Ignored...\n",
      "  dgl_warning(\"Unamed column is found. Ignored...\")\n",
      "/Users/andrechen/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset_base.py:298: DGLWarning: Unamed column is found. Ignored...\n",
      "  dgl_warning(\"Unamed column is found. Ignored...\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "82",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mCSVDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./graph_csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m dataset\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset.py:85\u001b[0m, in \u001b[0;36mCSVDataset.__init__\u001b[0;34m(self, data_path, force_reload, verbose, ndata_parser, edata_parser, gdata_parser, transform)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_yaml \u001b[39m=\u001b[39m load_yaml_with_sanity_check(meta_yaml_path)\n\u001b[1;32m     84\u001b[0m ds_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_yaml\u001b[39m.\u001b[39mdataset_name\n\u001b[0;32m---> 85\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(ds_name, raw_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mdirname(\n\u001b[1;32m     86\u001b[0m     meta_yaml_path), force_reload\u001b[39m=\u001b[39;49mforce_reload, verbose\u001b[39m=\u001b[39;49mverbose, transform\u001b[39m=\u001b[39;49mtransform)\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/dgl_dataset.py:99\u001b[0m, in \u001b[0;36mDGLDataset.__init__\u001b[0;34m(self, name, url, raw_dir, save_dir, hash_key, force_reload, verbose, transform)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_dir \u001b[39m=\u001b[39m save_dir\n\u001b[0;32m---> 99\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/dgl_dataset.py:191\u001b[0m, in \u001b[0;36mDGLDataset._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m load_flag:\n\u001b[1;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m    193\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset.py:122\u001b[0m, in \u001b[0;36mCSVDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m     graph_data \u001b[39m=\u001b[39m GraphData\u001b[39m.\u001b[39mload_from_csv(\n\u001b[1;32m    120\u001b[0m         meta_graph, base_dir\u001b[39m=\u001b[39mbase_dir, separator\u001b[39m=\u001b[39mmeta_yaml\u001b[39m.\u001b[39mseparator, data_parser\u001b[39m=\u001b[39mdata_parser)\n\u001b[1;32m    121\u001b[0m \u001b[39m# construct graphs\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraphs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m DGLGraphConstructor\u001b[39m.\u001b[39;49mconstruct_graphs(\n\u001b[1;32m    123\u001b[0m     node_data, edge_data, graph_data)\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mvalues())[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset_base.py:255\u001b[0m, in \u001b[0;36mDGLGraphConstructor.construct_graphs\u001b[0;34m(node_data, edge_data, graph_data)\u001b[0m\n\u001b[1;32m    253\u001b[0m     edge_data \u001b[39m=\u001b[39m [edge_data]\n\u001b[1;32m    254\u001b[0m node_dict \u001b[39m=\u001b[39m NodeData\u001b[39m.\u001b[39mto_dict(node_data)\n\u001b[0;32m--> 255\u001b[0m edge_dict \u001b[39m=\u001b[39m EdgeData\u001b[39m.\u001b[39;49mto_dict(edge_data, node_dict)\n\u001b[1;32m    256\u001b[0m graph_dict \u001b[39m=\u001b[39m DGLGraphConstructor\u001b[39m.\u001b[39m_construct_graphs(\n\u001b[1;32m    257\u001b[0m     node_dict, edge_dict)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m graph_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset_base.py:200\u001b[0m, in \u001b[0;36mEdgeData.to_dict\u001b[0;34m(edge_data, node_dict)\u001b[0m\n\u001b[1;32m    198\u001b[0m orig_dst_ids \u001b[39m=\u001b[39m e_data\u001b[39m.\u001b[39mdst[idx]\u001b[39m.\u001b[39mastype(node_dict[graph_id][dst_type][\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    199\u001b[0m src_ids \u001b[39m=\u001b[39m [src_mapping[index] \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m orig_src_ids]\n\u001b[0;32m--> 200\u001b[0m dst_ids \u001b[39m=\u001b[39m [dst_mapping[index] \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m orig_dst_ids]\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m graph_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m edge_dict:\n\u001b[1;32m    202\u001b[0m     edge_dict[graph_id] \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset_base.py:200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    198\u001b[0m orig_dst_ids \u001b[39m=\u001b[39m e_data\u001b[39m.\u001b[39mdst[idx]\u001b[39m.\u001b[39mastype(node_dict[graph_id][dst_type][\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    199\u001b[0m src_ids \u001b[39m=\u001b[39m [src_mapping[index] \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m orig_src_ids]\n\u001b[0;32m--> 200\u001b[0m dst_ids \u001b[39m=\u001b[39m [dst_mapping[index] \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m orig_dst_ids]\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m graph_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m edge_dict:\n\u001b[1;32m    202\u001b[0m     edge_dict[graph_id] \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mKeyError\u001b[0m: 82"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CSVDataset('./graph_csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
