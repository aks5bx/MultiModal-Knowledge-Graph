{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/tanyanaheta/desktop/nyu/y2s1/1006Capstone/NYU-Zillow-Capstone-2022-Team-A')\n",
    "import src.datamodules.SAGE as g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "dataset = dgl.data.CSVDataset('./graph_csv')\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1485, 4883, 2639,  ..., 2524, 2654, 1263])\n",
      "Total number of edges:  14631\n",
      "Total number of training edges:  13168\n",
      "Total number of testing edges:  1463\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "## Data Preperation Positive Edges \n",
    "######################\n",
    "\n",
    "test_frac = 0.1\n",
    "\n",
    "# Split edge set for training and testing\n",
    "u, v = g.edges()\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "\n",
    "\n",
    "\n",
    "test_size = int(len(eids) * test_frac)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "print(test_pos_u)\n",
    "\n",
    "print(\"Total number of edges: \", len(eids))\n",
    "print(\"Total number of training edges: \", train_size)\n",
    "print(\"Total number of testing edges: \", test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortened_adj_matrix = g.adjacency_matrix().clone().to_dense()\n",
    "# print(shortened_adj_matrix.size())\n",
    "# print(shortened_adj_matrix)\n",
    "# tag_loc = torch.ByteTensor(tag_mask)\n",
    "# print(tag_loc.size())\n",
    "# print(tag_loc)\n",
    "# shortened_adj_matrix = torch.transpose(torch.transpose(shortened_adj_matrix,0,1)[tag_loc], 0,1)\n",
    "# print(shortened_adj_matrix.size())\n",
    "\n",
    "\n",
    "# tag_mask = list(([1] * 80) + ([0] * 5000))\n",
    "# #print(tag_mask)\n",
    "# tag_loc = torch.ByteTensor(tag_mask)\n",
    "# print(tag_loc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True,  True,  ..., False, False, False])\n",
      "tensor([False, False, False,  ...,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# ## Negative Edges\n",
    "######################\n",
    "\n",
    "# Create all negative edges for this graph\n",
    "neg_edges = dgl.sampling.global_uniform_negative_sampling(g, 100000000)\n",
    "\n",
    "# First mask used to eliminate all tag nodes as source\n",
    "mask = neg_edges[0].lt(5000)\n",
    "print(mask)\n",
    "\n",
    "# Apply the mask to both source and destination nodes\n",
    "masked_neg = (torch.masked_select(neg_edges[0], mask), torch.masked_select(neg_edges[1], mask))\n",
    "\n",
    "# Second mask used to eliminate all image nodes as destination\n",
    "mask2 = masked_neg[1].ge(5000)\n",
    "print(mask2)\n",
    "\n",
    "# Apply the mask to both source and destination nodes\n",
    "masked_neg2 = (torch.masked_select(masked_neg[0], mask2), torch.masked_select(masked_neg[1], mask2))\n",
    "\n",
    "# Create a list of remaining source and destination nodes\n",
    "neg_u = (masked_neg2[0].tolist())\n",
    "neg_v = (masked_neg2[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all node features that can be imported to the graphs\n",
    "df = pd.read_csv('/Users/tanyanaheta/desktop/nyu/y2s1/1006Capstone/NYU-Zillow-Capstone-2022-Team-A/graph/graph_csv/coco_nodes.csv')\n",
    "df['featNew'] = df['feat'].apply(lambda x: [float(y) for y in x.split(\",\")])\n",
    "features = torch.Tensor(df['featNew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## Create Training Graph ##\n",
    "###########################\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Get the number of negative edges and split into train, test\n",
    "neg_eids_len = len(neg_u)\n",
    "test_size = int((neg_eids_len) * test_frac)\n",
    "train_size = neg_eids_len - test_size\n",
    "\n",
    "# Create source and destination nodes list for positive and negative graphs\n",
    "test_neg_u, test_neg_v = neg_u[:test_size], neg_v[:test_size]\n",
    "train_neg_u, train_neg_v = neg_u[test_size:], neg_v[test_size:]\n",
    "\n",
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v))\n",
    "train_pos_g.ndata['feat'] = features\n",
    "train_pos_g = train_pos_g.to(device)\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v)).to(device)\n",
    "test_pos_g.ndata['feat'] = features[0:5078]\n",
    "test_pos_g = test_pos_g.to(device)\n",
    "\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v)).to(device)\n",
    "train_neg_g.ndata['feat'] = features\n",
    "train_neg_g = train_neg_g.to(device)\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v)).to(device)\n",
    "test_neg_g.ndata['feat'] = features[0:5009]\n",
    "test_neg_g = test_neg_g.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## Predicton Function ##\n",
    "########################\n",
    "\n",
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(torch.nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g = g.to(device)\n",
    "            g.ndata['h'] = h.to(device)\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "class MLPPredictor(torch.nn.Module):\n",
    "    # def __init__(self, g):\n",
    "    #     super().__init__()\n",
    "    #     self.W1 = torch.nn.Linear(g.ndata['feat'] * 2, g.ndata['feat'])\n",
    "    #     self.W2 = torch.nn.Linear(g.ndata['feat'], 1)\n",
    "\n",
    "    # def apply_edges(self, edges):\n",
    "    #     \"\"\"\n",
    "    #     Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     edges :\n",
    "    #         Has three members ``src``, ``dst`` and ``data``, each of\n",
    "    #         which is a dictionary representing the features of the\n",
    "    #         source nodes, the destination nodes, and the edges\n",
    "    #         themselves.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     dict\n",
    "    #         A dictionary of new edge features.\n",
    "    #     \"\"\"\n",
    "    #     # clone_neg = test_neg_g \n",
    "    #     # h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "    #     # return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "\n",
    "\n",
    "    #     src_feat = []\n",
    "    #     dst_feat = []\n",
    "\n",
    "    #     # Feature array for the first node in the list of edges sourcenodes \n",
    "    #     g.ndata['feat'][g.all_edges()[0][0].item()]\n",
    "\n",
    "\n",
    "    #         # All the node features\n",
    "    #     # g.ndata['feat']\n",
    "    #         # Getting the source nodeID \n",
    "    #     #g.all_edges()[0][0].item()\n",
    "\n",
    "    #     #What we want \n",
    "    #     torch.cat(['src_feat', 'dst_feat'], 1)\n",
    "\n",
    "    # def forward(self, g, h):\n",
    "    #     with g.local_scope():\n",
    "    #         g.ndata['h'] = h\n",
    "    #         g.apply_edges(self.apply_edges)\n",
    "    #         return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## Training Loop - Setup ##\n",
    "###########################\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = g_train.SAGE(train_pos_g.ndata['feat'].shape[1], None ,train_pos_g.ndata['feat'].shape[1], 'mean')\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "#pred = MLPPredictor(16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "## Note: loss can be greater than one because labels are 1s and 0s \n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## Training Loop Execution ##\n",
    "#############################\n",
    "\n",
    "import itertools\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.05)\n",
    "\n",
    "for e in range(300):\n",
    "    # forward\n",
    "    h = model(train_pos_g, train_pos_g.ndata['feat']).to(device)\n",
    "    # print(type(h))\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.9861590617804803\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "## Evaluation ##\n",
    "################\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g.to(device), test_pos_g.ndata['feat'].to(device))\n",
    "    neg_score = pred(test_neg_g.to(device), test_neg_g.ndata['feat'].to(device))\n",
    "    print('AUC', compute_auc(pos_score, neg_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('coco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfc312b27b162c7e9f1679bb196f387dd54e7b8ef401a5376928ada2ff8bb869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
