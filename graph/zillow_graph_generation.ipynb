{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "from ast import literal_eval\n",
    "\n",
    "import torch\n",
    "import pydantic\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting list to dict: 100%|██████████| 1542/1542 [00:00<00:00, 2150138.55it/s]\n",
      "converting list to dict: 100%|██████████| 18/18 [00:00<00:00, 719023.54it/s]\n"
     ]
    }
   ],
   "source": [
    "image_embed_dict = joblib.load('../zillow_data/image_embed.joblib')\n",
    "keyword_embed_dict = {}\n",
    "scene_embed_dict = {}\n",
    "\n",
    "keyword_embed_dictlist = joblib.load('../zillow_data/keyword_embed.joblib')\n",
    "for dict in tqdm(keyword_embed_dictlist, desc='converting list to dict'):\n",
    "    dict_key = list(dict.keys())[0]\n",
    "    keyword_embed_dict[dict_key] = dict[dict_key]\n",
    "\n",
    "scene_embed_dictlist = joblib.load('../zillow_data/scene_embed.joblib')\n",
    "for dict in tqdm(scene_embed_dictlist, desc='converting list to dict'):\n",
    "    dict_key = list(dict.keys())[0]\n",
    "    scene_embed_dict[dict_key] = dict[dict_key]\n",
    "\n",
    "modal_dicts = {\n",
    "    'images': image_embed_dict,\n",
    "    'keywords': keyword_embed_dict,\n",
    "    'scenes': scene_embed_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique images count: 82720\n",
      "Unique keywords count: 1542\n",
      "Unique scenes count: 18\n"
     ]
    }
   ],
   "source": [
    "for modal in modal_dicts:\n",
    "    print(f'Unique {modal} count: {len(list(modal_dicts[modal].keys()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 130065\n",
      "Pct of images with at least one keyword: 0.2462076653980702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_hash</th>\n",
       "      <th>keyword_hash</th>\n",
       "      <th>image_hash</th>\n",
       "      <th>propertyIdhash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67e69903823c5a541b29be07e784b7e6</td>\n",
       "      <td>[]</td>\n",
       "      <td>8f1c8d0b5b7cc98231cdea9f923d928e</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60825cdcaad5cba560a6f63c895e1f3b</td>\n",
       "      <td>[851112d8c835d58c497101d9886a1348, b10a8c0bede...</td>\n",
       "      <td>f2d2571c7b9a1e124b188f84222be032</td>\n",
       "      <td>6b693c1082a8f8b747d0db60d179b7b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624109635107c411520779cf9c82ad65</td>\n",
       "      <td>[]</td>\n",
       "      <td>3feadc281c74873a6e55a4ab83ebd623</td>\n",
       "      <td>c871527ccd30371d69d21faa47008f12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624109635107c411520779cf9c82ad65</td>\n",
       "      <td>[]</td>\n",
       "      <td>71906fef662e966b21afa3d53b92decd</td>\n",
       "      <td>c871527ccd30371d69d21faa47008f12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624109635107c411520779cf9c82ad65</td>\n",
       "      <td>[]</td>\n",
       "      <td>163c91537b81f3ad637d9ceb771e2e1d</td>\n",
       "      <td>c871527ccd30371d69d21faa47008f12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         scene_hash  \\\n",
       "0  67e69903823c5a541b29be07e784b7e6   \n",
       "1  60825cdcaad5cba560a6f63c895e1f3b   \n",
       "2  624109635107c411520779cf9c82ad65   \n",
       "3  624109635107c411520779cf9c82ad65   \n",
       "4  624109635107c411520779cf9c82ad65   \n",
       "\n",
       "                                        keyword_hash  \\\n",
       "0                                                 []   \n",
       "1  [851112d8c835d58c497101d9886a1348, b10a8c0bede...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                         image_hash                    propertyIdhash  \n",
       "0  8f1c8d0b5b7cc98231cdea9f923d928e  a3d2de7675556553a5f08e4c88d2c228  \n",
       "1  f2d2571c7b9a1e124b188f84222be032  6b693c1082a8f8b747d0db60d179b7b2  \n",
       "2  3feadc281c74873a6e55a4ab83ebd623  c871527ccd30371d69d21faa47008f12  \n",
       "3  71906fef662e966b21afa3d53b92decd  c871527ccd30371d69d21faa47008f12  \n",
       "4  163c91537b81f3ad637d9ceb771e2e1d  c871527ccd30371d69d21faa47008f12  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_links = pd.read_csv('../zillow_data/NYU_photoboard_file.csv')\n",
    "\n",
    "# convert string object of image_keyword_hash column back to a list of keyword hashes\n",
    "node_links['image_keyword_hash'] = node_links['image_keyword_hash'].apply(lambda x: literal_eval(x))\n",
    "node_links = node_links.rename(columns={'url_hash': 'image_hash', 'image_keyword_hash': 'keyword_hash'})\n",
    "\n",
    "print('Total rows:', len(node_links))\n",
    "\n",
    "node_links_keywords_only = node_links[node_links['keyword_hash'].apply(lambda x: x!=[])]\n",
    "print('Pct of images with at least one keyword:', len(node_links_keywords_only) / len(node_links))\n",
    "node_links.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "test = node_links['scene_hash'].values\n",
    "test_lens = [len(x) for x in test]\n",
    "print(np.min(test_lens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying train masks: 100%|██████████| 82720/82720 [00:39<00:00, 2075.18it/s]\n",
      "applying val masks: 100%|██████████| 82720/82720 [00:09<00:00, 8374.65it/s]\n",
      "applying test masks: 100%|██████████| 82720/82720 [00:09<00:00, 8302.75it/s]\n",
      "formatting images node embeddings: 100%|██████████| 82720/82720 [00:18<00:00, 4439.27it/s]\n",
      "applying train masks: 100%|██████████| 1542/1542 [00:00<00:00, 147024.70it/s]\n",
      "applying val masks: 100%|██████████| 1542/1542 [00:00<00:00, 421425.48it/s]\n",
      "applying test masks: 100%|██████████| 1542/1542 [00:00<00:00, 411976.35it/s]\n",
      "formatting keywords node embeddings: 100%|██████████| 1542/1542 [00:00<00:00, 4415.02it/s]\n",
      "applying train masks: 100%|██████████| 18/18 [00:00<00:00, 119269.31it/s]\n",
      "applying val masks: 100%|██████████| 18/18 [00:00<00:00, 122560.83it/s]\n",
      "applying test masks: 100%|██████████| 18/18 [00:00<00:00, 113189.61it/s]\n",
      "formatting scenes node embeddings: 100%|██████████| 18/18 [00:00<00:00, 4384.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def train_val_test_ids(node_ids):\n",
    "    node_ids_copy = node_ids.copy()\n",
    "    random.shuffle(node_ids_copy)\n",
    "    n = len(node_ids_copy)\n",
    "    train_ct, val_ct = [math.floor(n*0.7), math.ceil(n*0.15)]\n",
    "    return [node_ids_copy[0:train_ct], node_ids_copy[train_ct:train_ct+val_ct], node_ids_copy[train_ct+val_ct:]]\n",
    "\n",
    "def split_mask(node_id, split_ids):\n",
    "    return True if node_id in split_ids else False\n",
    "\n",
    "def nodes_table(modal, modal_dict):\n",
    "    node_ids = list(modal_dict.keys())\n",
    "    nodes = pd.DataFrame({'node_id': list(node_ids)})\n",
    "    train_ids, val_ids, test_ids = train_val_test_ids(node_ids)\n",
    "\n",
    "    tqdm.pandas(desc='applying train masks')\n",
    "    nodes['train_mask'] = nodes['node_id'].progress_apply(lambda x: split_mask(x, train_ids))\n",
    "    tqdm.pandas(desc='applying val masks')\n",
    "    nodes['val_mask'] = nodes['node_id'].progress_apply(lambda x: split_mask(x, val_ids))\n",
    "    tqdm.pandas(desc='applying test masks')\n",
    "    nodes['test_mask'] = nodes['node_id'].progress_apply(lambda x: split_mask(x, test_ids))\n",
    "    \n",
    "    tqdm.pandas(desc=f'formatting {modal} node embeddings')\n",
    "    nodes['feat'] = nodes['node_id'].progress_apply(lambda x: ', '.join([str(y) for y in modal_dict[x].tolist()]))\n",
    "\n",
    "    return nodes\n",
    "\n",
    "nodes_table_modals = pd.DataFrame()\n",
    "for modal in modal_dicts:\n",
    "    nodes_table_modals = pd.concat([nodes_table_modals, nodes_table(modal, modal_dicts[modal])])\n",
    "\n",
    "nodes_table_modals['node_id'].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84280\n",
      "84275\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>train_mask</th>\n",
       "      <th>val_mask</th>\n",
       "      <th>test_mask</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e8ca9e20156cff1b5166093249a1a808</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.019534708932042122, -0.008678311482071877, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b4f1031b484ce309932faab718593e5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.020777437835931778, 0.007536700926721096, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54ea244b01d4fe7bcfb8910e1b16e2da</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.012318197637796402, 0.002343656960874796, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3fde20991fe86c0b28b70c050c2c7d5b</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.03275497257709503, 0.01234776247292757, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d14b527f68e2b30ced4d2ddc9d18ff83</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.027265874668955803, -0.010033353231847286, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            node_id  train_mask  val_mask  test_mask  \\\n",
       "0  e8ca9e20156cff1b5166093249a1a808       False     False       True   \n",
       "1  0b4f1031b484ce309932faab718593e5        True     False      False   \n",
       "2  54ea244b01d4fe7bcfb8910e1b16e2da        True     False      False   \n",
       "3  3fde20991fe86c0b28b70c050c2c7d5b       False     False       True   \n",
       "4  d14b527f68e2b30ced4d2ddc9d18ff83        True     False      False   \n",
       "\n",
       "                                                feat  \n",
       "0  -0.019534708932042122, -0.008678311482071877, ...  \n",
       "1  -0.020777437835931778, 0.007536700926721096, -...  \n",
       "2  -0.012318197637796402, 0.002343656960874796, 0...  \n",
       "3  0.03275497257709503, 0.01234776247292757, -0.0...  \n",
       "4  -0.027265874668955803, -0.010033353231847286, ...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data into edges: 130065it [01:46, 1224.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>dst_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f1c8d0b5b7cc98231cdea9f923d928e</td>\n",
       "      <td>67e69903823c5a541b29be07e784b7e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2d2571c7b9a1e124b188f84222be032</td>\n",
       "      <td>60825cdcaad5cba560a6f63c895e1f3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2d2571c7b9a1e124b188f84222be032</td>\n",
       "      <td>851112d8c835d58c497101d9886a1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2d2571c7b9a1e124b188f84222be032</td>\n",
       "      <td>b10a8c0bede9eb4ea771b04db3149f28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f2d2571c7b9a1e124b188f84222be032</td>\n",
       "      <td>6160972776d990112e5df1ceb938816c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             src_id                            dst_id\n",
       "0  8f1c8d0b5b7cc98231cdea9f923d928e  67e69903823c5a541b29be07e784b7e6\n",
       "0  f2d2571c7b9a1e124b188f84222be032  60825cdcaad5cba560a6f63c895e1f3b\n",
       "1  f2d2571c7b9a1e124b188f84222be032  851112d8c835d58c497101d9886a1348\n",
       "2  f2d2571c7b9a1e124b188f84222be032  b10a8c0bede9eb4ea771b04db3149f28\n",
       "3  f2d2571c7b9a1e124b188f84222be032  6160972776d990112e5df1ceb938816c"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Notes about the node_links dataframe:\n",
    "    - ~130,000 total roows\n",
    "    - scene_hash is always populated\n",
    "    - keywords_hash is a list of keyword hashes, usually an empty list (at least one entry for ~25% of images)\n",
    "'''\n",
    "\n",
    "def edges_table(node_links):\n",
    "    edges = pd.DataFrame(columns=['src_id', 'dst_id'])\n",
    "    for idx, row in tqdm(node_links.iterrows(), desc='parsing data into edges'):\n",
    "        edges_subset = {'src_id': [], 'dst_id': []}\n",
    "        edges_subset['src_id'].append(row['image_hash'])\n",
    "        edges_subset['dst_id'].append(row['scene_hash'])\n",
    "        for keyword in row['keyword_hash']:\n",
    "            edges_subset['src_id'].append(row['image_hash'])\n",
    "            edges_subset['dst_id'].append(keyword)\n",
    "        edges = pd.concat([edges, pd.DataFrame(edges_subset)])\n",
    "\n",
    "    return edges\n",
    "\n",
    "edges = edges_table(node_links)\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store graph csv files\n",
    "\n",
    "if not os.path.exists('zillow_graph_csv'):\n",
    "    os.mkdir('zillow_graph_csv')\n",
    "\n",
    "edges.to_csv('zillow_graph_csv/zillow_edges.csv', index=False)\n",
    "nodes_table_modals_nodup.to_csv('zillow_graph_csv/zillow_nodes.csv', index=False)\n",
    "\n",
    "g_metadata = {\n",
    "    'dataset_name': 'zillow_graph',\n",
    "    'edge_data': [{'file_name': 'zillow_edges.csv'}],\n",
    "    'node_data': [{'file_name': 'zillow_nodes.csv'}]\n",
    "}\n",
    "\n",
    "with open('zillow_graph_csv/meta.yaml', 'w') as file:\n",
    "    yaml.dump(g_metadata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84275\n",
      "84270\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('zillow_graph_csv/zillow_nodes.csv')\n",
    "print(len(test))\n",
    "test2 = test['node_id'].drop_duplicates()\n",
    "print(len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Node IDs are required to be unique but the following ids are duplicate: ['67518d646b9c9868b149f513ba47af66' '67e69903823c5a541b29be07e784b7e6'\n 'a203591a109f718f46c029211a7dc295' 'cff8b1fe936268ff7a363b5dc5f5fdf6'\n 'e451bdad985636f1160872c46485b2ff']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m zillow_graph_dataset \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mCSVDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./zillow_graph_csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m zillow_graph_dataset\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset.py:85\u001b[0m, in \u001b[0;36mCSVDataset.__init__\u001b[0;34m(self, data_path, force_reload, verbose, ndata_parser, edata_parser, gdata_parser, transform)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_yaml \u001b[39m=\u001b[39m load_yaml_with_sanity_check(meta_yaml_path)\n\u001b[1;32m     84\u001b[0m ds_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_yaml\u001b[39m.\u001b[39mdataset_name\n\u001b[0;32m---> 85\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(ds_name, raw_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mdirname(\n\u001b[1;32m     86\u001b[0m     meta_yaml_path), force_reload\u001b[39m=\u001b[39;49mforce_reload, verbose\u001b[39m=\u001b[39;49mverbose, transform\u001b[39m=\u001b[39;49mtransform)\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/dgl_dataset.py:99\u001b[0m, in \u001b[0;36mDGLDataset.__init__\u001b[0;34m(self, name, url, raw_dir, save_dir, hash_key, force_reload, verbose, transform)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_dir \u001b[39m=\u001b[39m save_dir\n\u001b[0;32m---> 99\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/dgl_dataset.py:191\u001b[0m, in \u001b[0;36mDGLDataset._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m load_flag:\n\u001b[1;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m    193\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset.py:122\u001b[0m, in \u001b[0;36mCSVDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m     graph_data \u001b[39m=\u001b[39m GraphData\u001b[39m.\u001b[39mload_from_csv(\n\u001b[1;32m    120\u001b[0m         meta_graph, base_dir\u001b[39m=\u001b[39mbase_dir, separator\u001b[39m=\u001b[39mmeta_yaml\u001b[39m.\u001b[39mseparator, data_parser\u001b[39m=\u001b[39mdata_parser)\n\u001b[1;32m    121\u001b[0m \u001b[39m# construct graphs\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraphs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m DGLGraphConstructor\u001b[39m.\u001b[39;49mconstruct_graphs(\n\u001b[1;32m    123\u001b[0m     node_data, edge_data, graph_data)\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mvalues())[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset_base.py:254\u001b[0m, in \u001b[0;36mDGLGraphConstructor.construct_graphs\u001b[0;34m(node_data, edge_data, graph_data)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_data, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    253\u001b[0m     edge_data \u001b[39m=\u001b[39m [edge_data]\n\u001b[0;32m--> 254\u001b[0m node_dict \u001b[39m=\u001b[39m NodeData\u001b[39m.\u001b[39;49mto_dict(node_data)\n\u001b[1;32m    255\u001b[0m edge_dict \u001b[39m=\u001b[39m EdgeData\u001b[39m.\u001b[39mto_dict(edge_data, node_dict)\n\u001b[1;32m    256\u001b[0m graph_dict \u001b[39m=\u001b[39m DGLGraphConstructor\u001b[39m.\u001b[39m_construct_graphs(\n\u001b[1;32m    257\u001b[0m     node_dict, edge_dict)\n",
      "File \u001b[0;32m~/.pyenv/versions/capstone/lib/python3.8/site-packages/dgl/data/csv_dataset_base.py:144\u001b[0m, in \u001b[0;36mNodeData.to_dict\u001b[0;34m(node_data)\u001b[0m\n\u001b[1;32m    141\u001b[0m u_ids, u_indices, u_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(\n\u001b[1;32m    142\u001b[0m     ids, return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ids) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(u_ids):\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mraise\u001b[39;00m DGLError(\u001b[39m\"\u001b[39m\u001b[39mNode IDs are required to be unique but the following ids are duplicate: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    145\u001b[0m         u_ids[u_counts \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m]))\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m graph_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m node_dict:\n\u001b[1;32m    147\u001b[0m     node_dict[graph_id] \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mDGLError\u001b[0m: Node IDs are required to be unique but the following ids are duplicate: ['67518d646b9c9868b149f513ba47af66' '67e69903823c5a541b29be07e784b7e6'\n 'a203591a109f718f46c029211a7dc295' 'cff8b1fe936268ff7a363b5dc5f5fdf6'\n 'e451bdad985636f1160872c46485b2ff']"
     ]
    }
   ],
   "source": [
    "zillow_graph_dataset = dgl.data.CSVDataset('./zillow_graph_csv')\n",
    "zillow_graph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = zillow_graph_dataset[0]\n",
    "options = {\n",
    "    'node_color': 'blue',\n",
    "    'node_size': 10,\n",
    "    'width': 1,\n",
    "}\n",
    "G = dgl.to_networkx(g)\n",
    "plt.figure(figsize=[15,7])\n",
    "nx.draw(G, **options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0cec99272687ff68ec9f493d8a42393208c2c11e01f8f3ef9968b29a52d5460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
