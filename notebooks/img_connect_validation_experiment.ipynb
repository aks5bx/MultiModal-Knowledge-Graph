{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/zillow_MMKG/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Simulate having cfg available by loading in hydra config as dict\n",
    "import yaml\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "\n",
    "import pyrootutils\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import MeanMetric\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAveragePrecision\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from IPython.display import clear_output\n",
    "\n",
    "user_net_id = os.getlogin()\n",
    "home_path = '/scratch/' + user_net_id + '/projects/NYU-Zillow-Capstone-2022-Team-A'\n",
    "if home_path not in sys.path:\n",
    "    sys.path.append('/scratch/' + user_net_id + '/projects/NYU-Zillow-Capstone-2022-Team-A')\n",
    "\n",
    "from src.datamodules.negative_sampler import NegativeSampler\n",
    "from src.model.SAGE import SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bidirected_with_reverse_mapping(g):\n",
    "    \"\"\"Makes a graph bidirectional, and returns a mapping array ``mapping`` where ``mapping[i]``\n",
    "    is the reverse edge of edge ID ``i``. Does not work with graphs that have self-loops.\n",
    "    \"\"\"\n",
    "    g_simple, mapping = dgl.to_simple(\n",
    "        dgl.add_reverse_edges(g), return_counts=\"count\", writeback_mapping=True\n",
    "    )\n",
    "    c = g_simple.edata[\"count\"]\n",
    "    num_edges = g.num_edges()\n",
    "    mapping_offset = torch.zeros(g_simple.num_edges() + 1, dtype=g_simple.idtype)\n",
    "    mapping_offset[1:] = c.cumsum(0)\n",
    "    idx = mapping.argsort()\n",
    "    idx_uniq = idx[mapping_offset[:-1]]\n",
    "    reverse_idx = torch.where(\n",
    "        idx_uniq >= num_edges, idx_uniq - num_edges, idx_uniq + num_edges\n",
    "    )\n",
    "    reverse_mapping = mapping[reverse_idx]\n",
    "    # sanity check\n",
    "    src1, dst1 = g_simple.edges()\n",
    "    src2, dst2 = g_simple.find_edges(reverse_mapping)\n",
    "    assert torch.equal(src1, dst2)\n",
    "    assert torch.equal(src2, dst1)\n",
    "    return g_simple, reverse_mapping\n",
    "\n",
    "\n",
    "class NegativeSamplerTest(object):\n",
    "    def __init__(self, g, k, max_img_id, keyword_as_src, neg_share=False):\n",
    "        self.weights = g.in_degrees().float() ** 0.75\n",
    "        self.k = k\n",
    "        self.neg_share = neg_share\n",
    "        self.max_img_id = max_img_id\n",
    "        self.keyword_as_src = keyword_as_src\n",
    "\n",
    "    def __call__(self, g, eids):\n",
    "        src, _ = g.find_edges(eids)\n",
    "        if self.keyword_as_src == False:\n",
    "            img_node_mask = src <= self.max_img_id\n",
    "            src = src[img_node_mask]\n",
    "        n = len(src)\n",
    "\n",
    "        if self.neg_share and n % self.k == 0:\n",
    "            dst = self.weights.multinomial(n, replacement=True)\n",
    "            dst = dst.view(-1, 1, self.k).expand(-1, self.k, -1).flatten()\n",
    "        else:\n",
    "            dst = self.weights.multinomial(n * self.k, replacement=True)\n",
    "            \n",
    "        src = src.repeat_interleave(self.k)\n",
    "        return src, dst\n",
    "\n",
    "class DataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_dataset_root,\n",
    "        modal_node_ids_file,\n",
    "        keyword_as_src=False,\n",
    "        data_cpu=False,\n",
    "        fan_out=[10, 25],\n",
    "        device=\"cpu\",\n",
    "        batch_size=1024,\n",
    "        num_workers=4,\n",
    "        force_reload=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        dataset = dgl.data.CSVDataset(csv_dataset_root, force_reload=force_reload)\n",
    "        g = dataset[0]\n",
    "        g_bid, reverse_eids = to_bidirected_with_reverse_mapping(g)\n",
    "        g_bid = g_bid.to(device)\n",
    "        g = g.to(device)\n",
    "        reverse_eids = reverse_eids.to(device)\n",
    "\n",
    "        max_img_id = max(json.load(open(modal_node_ids_file, 'r'))['images'])\n",
    "\n",
    "        train_nid = torch.nonzero(g_bid.ndata[\"train_mask\"], as_tuple=True)[0].to(device)\n",
    "        val_nid = torch.nonzero(g_bid.ndata[\"val_mask\"], as_tuple=True)[0].to(device)\n",
    "        test_nid = torch.nonzero(\n",
    "            ~(g_bid.ndata[\"train_mask\"] | g_bid.ndata[\"val_mask\"]), as_tuple=True\n",
    "        )[0].to(device)\n",
    "\n",
    "        sampler = dgl.dataloading.MultiLayerNeighborSampler(\n",
    "            [int(_) for _ in fan_out], prefetch_node_feats=[\"feat\"]\n",
    "        )\n",
    "\n",
    "        self.g = g\n",
    "        self.g_bid = g_bid\n",
    "        self.train_nid, self.val_nid, self.test_nid = train_nid, val_nid, test_nid\n",
    "        self.sampler = sampler\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.in_dim = g_bid.ndata[\"feat\"].shape[1]\n",
    "        self.reverse_eids = reverse_eids\n",
    "        self.max_img_id = max_img_id\n",
    "        self.keyword_as_src = keyword_as_src\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        edge_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "            self.sampler,\n",
    "            exclude='reverse_id',\n",
    "            reverse_eids=self.reverse_eids,\n",
    "            negative_sampler=NegativeSamplerTest(self.g, 1, self.max_img_id, self.keyword_as_src)\n",
    "        )\n",
    "\n",
    "        train_subgraph = self.g_bid.subgraph(self.train_nid)\n",
    "        train_u, train_v = train_subgraph.edges()\n",
    "        train_eids = train_subgraph.edata['_ID'][train_subgraph.edge_ids(train_u, train_v)]\n",
    "\n",
    "        return dgl.dataloading.DataLoader(\n",
    "            self.g_bid,\n",
    "            train_eids,\n",
    "            edge_sampler,\n",
    "            device=self.device,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        edge_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "            self.sampler,\n",
    "        )\n",
    "\n",
    "        val_subgraph = self.g_bid.subgraph(self.val_nid)\n",
    "        val_u, val_v = val_subgraph.edges()\n",
    "        val_eids = val_subgraph.edata['_ID'][val_subgraph.edge_ids(val_u, val_v)]\n",
    "\n",
    "        return dgl.dataloading.DataLoader(\n",
    "            self.g_bid,\n",
    "            val_eids,\n",
    "            edge_sampler,\n",
    "            device=self.device,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        edge_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "            self.sampler,\n",
    "        )\n",
    "\n",
    "        test_subgraph = self.g_bid.subgraph(self.test_nid)\n",
    "        test_u, test_v = test_subgraph.edges()\n",
    "        test_eids = test_subgraph.edata['_ID'][test_subgraph.edge_ids(test_u, test_v)]\n",
    "\n",
    "        return dgl.dataloading.DataLoader(\n",
    "            self.g_bid,\n",
    "            test_eids,\n",
    "            edge_sampler,\n",
    "            device=self.device,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "class ScorePredictor(nn.Module):\n",
    "    def forward(self, edge_subgraph, x):\n",
    "        with edge_subgraph.local_scope():\n",
    "            edge_subgraph.ndata[\"h\"] = x\n",
    "            edge_subgraph.ndata['h_norm'] = F.normalize(x, p=2, dim=-1)\n",
    "            edge_subgraph.apply_edges(fn.u_dot_v(\"h_norm\", \"h_norm\", \"score\"))\n",
    "            return edge_subgraph.edata[\"score\"]\n",
    "\n",
    "class SAGELightning(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        h_dim,\n",
    "        n_layers=3,\n",
    "        activation=F.relu,\n",
    "        dropout=0,\n",
    "        sage_conv_method=\"mean\",\n",
    "        lr=0.0005,\n",
    "        batch_size=1024,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.module = SAGE(\n",
    "            in_dim, h_dim, n_layers, activation, dropout, sage_conv_method\n",
    "        )\n",
    "        self.lr = lr\n",
    "        self.predictor = ScorePredictor()\n",
    "        self.batch_size = batch_size\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.train_loss = MeanMetric()\n",
    "        self.mean_val_positive_score = MeanMetric()\n",
    "    \n",
    "    def forward(self, graph, blocks, x):\n",
    "        self.module(graph, blocks, x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_nodes, pos_graph, neg_graph, blocks = batch\n",
    "        x = blocks[0].srcdata[\"feat\"]\n",
    "        logits = self.module(blocks, x)\n",
    "        pos_score = self.predictor(pos_graph, logits)\n",
    "        neg_score = self.predictor(neg_graph, logits)\n",
    "\n",
    "        score = torch.cat([pos_score, neg_score])\n",
    "        pos_label = torch.ones_like(pos_score)\n",
    "        neg_label = torch.zeros_like(neg_score)\n",
    "        labels = torch.cat([pos_label, neg_label])\n",
    "        loss = F.binary_cross_entropy_with_logits(score, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_nodes, pos_graph, blocks = batch\n",
    "        x = blocks[0].srcdata[\"feat\"]\n",
    "        logits = self.module(blocks, x)\n",
    "        pos_score = self.predictor(pos_graph, logits)\n",
    "        pos_label = torch.ones_like(pos_score)\n",
    "        self.mean_val_positive_score(pos_score)\n",
    "\n",
    "        self.log(\n",
    "            \"mean_val_positive_score\",\n",
    "            self.mean_val_positive_score,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set WD location to /scratch/alc9635/projects/NYU-Zillow-Capstone-2022-Team-A\n"
     ]
    }
   ],
   "source": [
    "class NestedNamespace(SimpleNamespace):\n",
    "    def __init__(self, dictionary, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for key, value in dictionary.items():\n",
    "            if isinstance(value, dict):\n",
    "                self.__setattr__(key, NestedNamespace(value))\n",
    "            else:\n",
    "                self.__setattr__(key, value)\n",
    "\n",
    "root_path = pyrootutils.find_root(search_from='train_graphsage_explore.ipynb', indicator=\".git\")\n",
    "print('Set WD location to', root_path)\n",
    "pyrootutils.set_root(\n",
    "    path=root_path,\n",
    "    project_root_env_var=True,\n",
    "    dotenv=True,\n",
    "    pythonpath=True,\n",
    "    cwd=True\n",
    ")\n",
    "\n",
    "cfg = NestedNamespace(yaml.load(open('conf/config.yaml'), Loader=Loader))\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type           | Params\n",
      "-----------------------------------------------------------\n",
      "0 | module                  | SAGE           | 1.6 M \n",
      "1 | predictor               | ScorePredictor | 0     \n",
      "2 | train_loss              | MeanMetric     | 0     \n",
      "3 | mean_val_positive_score | MeanMetric     | 0     \n",
      "-----------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.298     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/zillow_MMKG/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:135: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "  rank_zero_warn(\n",
      "/ext3/conda/zillow_MMKG/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 160 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/ext3/conda/zillow_MMKG/lib/python3.8/site-packages/lightning_lite/utilities/data.py:63: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/zillow_MMKG/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 160 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 227/227 [00:06<00:00, 36.33it/s, loss=0.479, v_num=436, mean_val_positive_score=0.963]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 227/227 [00:06<00:00, 35.95it/s, loss=0.479, v_num=436, mean_val_positive_score=0.963]\n"
     ]
    }
   ],
   "source": [
    "# Vanilla Graph Training\n",
    "org = 'zillow'\n",
    "\n",
    "if org == 'coco':\n",
    "    csv_dataset_root = cfg.data.coco_graph_root\n",
    "elif org == 'zillow':\n",
    "    csv_dataset_root = cfg.data.zillow_root\n",
    "\n",
    "modal_node_ids_file = os.path.join(csv_dataset_root,'modal_node_ids.json')\n",
    "datamodule = DataModule(\n",
    "    csv_dataset_root, \n",
    "    modal_node_ids_file, \n",
    "    keyword_as_src=False, \n",
    "    device=device, \n",
    "    batch_size=cfg.training.batch_size, \n",
    "    force_reload=False\n",
    ")\n",
    "\n",
    "model = SAGELightning(\n",
    "    datamodule.in_dim,\n",
    "    cfg.model.hidden_dim,\n",
    "    n_layers=cfg.model.n_layers,\n",
    "    batch_size=cfg.training.batch_size,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"mean_val_positive_score\", save_top_k=1, mode=\"max\"\n",
    ")\n",
    "trainer = Trainer(accelerator=\"gpu\", max_epochs=1, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of val img nodes: 12496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing image matches: 100%|██████████| 12496/12496 [00:02<00:00, 4654.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match stats:\n",
      "min matches: 1\n",
      "max matches: 414\n",
      "avg matches: 6.366437259923176\n",
      "std matches: 22.694494916935167\n",
      "total new edges to add: 79555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=71651, num_edges=349518,\n",
       "      ndata_schemes={'feat': Scheme(shape=(512,), dtype=torch.float32), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'ntype': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.uint8), 'train_mask': Scheme(shape=(), dtype=torch.uint8), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################\n",
    "#### Build train + validation eval_graph, where we connect ####\n",
    "#### val and train subgraph by introducing edges between   ####\n",
    "#### images in each subgraph based on cosine similarity    ####\n",
    "###############################################################\n",
    "\n",
    "# Step 1: Initialize val and eval subgraph\n",
    "val_subgraph = datamodule.g_bid.subgraph(datamodule.val_nid)\n",
    "eval_subgraph = datamodule.g_bid.subgraph(datamodule.train_nid) \n",
    "\n",
    "# Step 2: Add all nodes from val_subgraph to eval_subgraph (no edges yet - these will be added based on cosine similarity)\n",
    "val_img_node_idxs = (val_subgraph.ndata['ntype'] == 0).nonzero().squeeze()\n",
    "val_img_embeds = val_subgraph.ndata['feat'][val_img_node_idxs]\n",
    "val_img_node_ids = val_subgraph.ndata['_ID'][val_img_node_idxs]\n",
    "print('number of val img nodes:', len(val_img_node_ids))\n",
    "\n",
    "val_nodes_data = {'train_mask': torch.zeros(len(val_img_node_ids), dtype=torch.uint8).to(device),\n",
    "                  'val_mask': torch.ones(len(val_img_node_ids), dtype=torch.uint8).to(device),\n",
    "                  'test_mask': torch.zeros(len(val_img_node_ids), dtype=torch.uint8).to(device),\n",
    "                  'ntype': torch.zeros(len(val_img_node_ids), dtype=torch.int64).to(device),\n",
    "                  'feat': val_img_embeds.to(device),\n",
    "                  '_ID': val_img_node_ids}\n",
    "\n",
    "eval_subgraph.add_nodes(num=len(val_img_node_ids), data=val_nodes_data)\n",
    "\n",
    "# Step 3: Identify image node pairs as edges\n",
    "\n",
    "def get_cosine_sim(A, B):\n",
    "    '''\n",
    "    Given matrix A of vectors axd and a matrix B bxd for comparison, \n",
    "    give the cosine similarities between the rows of A and every row in B\n",
    "\n",
    "    Returns axb-sized array of cosine similarities\n",
    "    '''\n",
    "    cosine_sims = metrics.pairwise.cosine_similarity(A, B)\n",
    "\n",
    "    return cosine_sims\n",
    "\n",
    "eval_train_img_node_idxs = ((eval_subgraph.ndata['ntype'] == 0)&(eval_subgraph.ndata['train_mask']==1)).nonzero().squeeze()\n",
    "eval_val_img_node_idxs = ((eval_subgraph.ndata['ntype'] == 0)&(eval_subgraph.ndata['val_mask']==1)).nonzero().squeeze()\n",
    "eval_train_img_embeds = eval_subgraph.ndata['feat'][eval_train_img_node_idxs]\n",
    "eval_val_img_embeds = eval_subgraph.ndata['feat'][eval_val_img_node_idxs]\n",
    "\n",
    "cosine_sims_matrix = get_cosine_sim(eval_val_img_embeds.cpu().detach().numpy(), eval_train_img_embeds.cpu().detach().numpy())\n",
    "sim_threshold = 0.975\n",
    "        \n",
    "image_matches = []\n",
    "for cosine_sims in tqdm(cosine_sims_matrix, desc='computing image matches'):\n",
    "    eval_train_node_id_matches = eval_train_img_node_idxs[(cosine_sims>sim_threshold)]\n",
    "    if len(eval_train_node_id_matches) == 0:\n",
    "        eval_train_node_id_matches = eval_train_img_node_idxs[np.argmax(cosine_sims)].unsqueeze(0)\n",
    "    image_matches.append(eval_train_node_id_matches.tolist())\n",
    "\n",
    "matches_per_img = [len(matches) for matches in image_matches]\n",
    "print('match stats:')\n",
    "print(f'min matches: {np.min(matches_per_img)}')\n",
    "print(f'max matches: {np.max(matches_per_img)}')\n",
    "print(f'avg matches: {np.mean(matches_per_img)}')\n",
    "print(f'std matches: {np.std(matches_per_img)}')\n",
    "print(f'total new edges to add: {sum(matches_per_img)}')\n",
    "\n",
    "# Step 4: Add the edges to eval_subgraph\n",
    "\n",
    "u = []\n",
    "v = []\n",
    "\n",
    "for i in range(len(image_matches)):\n",
    "    val_img_node = eval_val_img_node_idxs[i].item()\n",
    "    train_img_matches = image_matches[i]\n",
    "    for node_id in train_img_matches:\n",
    "        train_img_node = node_id\n",
    "        # Add bidirectional edge for each match\n",
    "        u += [val_img_node, train_img_node]\n",
    "        v += [train_img_node, val_img_node]\n",
    "\n",
    "edge_data = {'_ID': torch.arange(torch.max(eval_subgraph.edata['_ID'])+1, torch.max(eval_subgraph.edata['_ID'])+1+len(u), dtype=torch.int64).to(device)}\n",
    "eval_subgraph.add_edges(torch.LongTensor(u).to(device), torch.LongTensor(v).to(device), data=edge_data)\n",
    "eval_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Turn DGL graph into DataLoader object for GraphSAGE forward inference\n",
    "\n",
    "u_eval, v_eval = eval_subgraph.edges()\n",
    "eval_subgraph_eids = eval_subgraph.edge_ids(u_eval, v_eval)\n",
    "layer_sampler = dgl.dataloading.NeighborSampler(fanouts=[10]) # During message passing between GNN layers, each node accept messages from a maximum of 25 incoming nodes\n",
    "batch_size = len(eval_subgraph.edges()[0])\n",
    "\n",
    "def eval_dataloader(g, layer_sampler, batch_size, eids):\n",
    "    edge_sampler = dgl.dataloading.as_edge_prediction_sampler(layer_sampler)\n",
    "\n",
    "    return dgl.dataloading.DataLoader(\n",
    "        g,\n",
    "        eids,\n",
    "        edge_sampler,\n",
    "        device=device,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "        # num_workers=self.num_workers,\n",
    "    )\n",
    "\n",
    "eval_dl = eval_dataloader(eval_subgraph, layer_sampler, batch_size, eval_subgraph_eids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=71562, num_edges=349518,\n",
      "      ndata_schemes={'feat': Scheme(shape=(512,), dtype=torch.float32), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'ntype': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.uint8), 'train_mask': Scheme(shape=(), dtype=torch.uint8), '_ID': Scheme(shape=(), dtype=torch.int64), 'feat_pred_norm': Scheme(shape=(512,), dtype=torch.float32)}\n",
      "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run graphSAGE forward inference over entire val_subgraph message flow graph (MFG)\n",
    "\n",
    "for batch in eval_dl:\n",
    "    # This loop only runs once b/c batch_size = number of total edges in train_val_subgraph - we only need it to get \"blocks\"\n",
    "    inputs, eval_subgraph, blocks = batch\n",
    "    \n",
    "x = blocks[0].srcdata[\"feat\"]\n",
    "model = model.to(device)\n",
    "logits = model.module(blocks, x)\n",
    "\n",
    "eval_subgraph.ndata['feat_pred_norm'] = F.normalize(logits, p=2, dim=-1)\n",
    "print(eval_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Extract validation image features and keyword features for \n",
    "eval_val_img_node_ids = ((eval_subgraph.ndata['val_mask']==1)&(eval_subgraph.ndata['ntype']==0)).nonzero().squeeze()\n",
    "eval_keyword_node_ids = ((eval_subgraph.ndata['ntype']==1)).nonzero().squeeze()\n",
    "\n",
    "eval_val_img_feat_preds = eval_subgraph.ndata['feat_pred_norm'][eval_val_img_node_ids]\n",
    "eval_keyword_feat_preds = eval_subgraph.ndata['feat_pred_norm'][eval_keyword_node_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0524, 0.0000,  ..., 0.0014, 0.0412, 0.0000],\n",
      "        [0.0000, 0.0806, 0.0000,  ..., 0.0000, 0.0459, 0.0000],\n",
      "        [0.0000, 0.0708, 0.0000,  ..., 0.0000, 0.0407, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0529, 0.0000,  ..., 0.0072, 0.0426, 0.0000],\n",
      "        [0.0000, 0.1267, 0.0000,  ..., 0.0000, 0.0125, 0.0050],\n",
      "        [0.0000, 0.0387, 0.0000,  ..., 0.0071, 0.0428, 0.0000]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0.0000, 0.0823, 0.0000,  ..., 0.0213, 0.0148, 0.1061],\n",
      "        [0.0000, 0.0852, 0.0000,  ..., 0.0004, 0.0318, 0.1095],\n",
      "        [0.0000, 0.0872, 0.0000,  ..., 0.0000, 0.0370, 0.1036],\n",
      "        ...,\n",
      "        [0.0000, 0.0407, 0.0000,  ..., 0.0000, 0.0489, 0.0862],\n",
      "        [0.0000, 0.0914, 0.0000,  ..., 0.0000, 0.0822, 0.0000],\n",
      "        [0.0000, 0.0558, 0.0000,  ..., 0.0000, 0.0870, 0.0336]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(eval_val_img_feat_preds)\n",
    "print(eval_keyword_feat_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8a98180768ec50653acfbae9679ecd2014a1d8366e4dd2cee9bea05835201d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
