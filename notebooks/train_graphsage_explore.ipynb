{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/zillow_MMKG/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Simulate having cfg available by loading in hydra config as dict\n",
    "import yaml\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import MeanMetric\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "user_net_id = os.getlogin()\n",
    "home_path = '/scratch/' + user_net_id + '/projects/NYU-Zillow-Capstone-2022-Team-A'\n",
    "if home_path not in sys.path:\n",
    "    sys.path.append('/scratch/' + user_net_id + '/projects/NYU-Zillow-Capstone-2022-Team-A')\n",
    "\n",
    "from src.datamodules.negative_sampler import NegativeSampler\n",
    "from src.model.SAGE import SAGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate having cfg available by loading in hydra config as dict\n",
    "from types import SimpleNamespace\n",
    "\n",
    "class NestedNamespace(SimpleNamespace):\n",
    "    def __init__(self, dictionary, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for key, value in dictionary.items():\n",
    "            if isinstance(value, dict):\n",
    "                self.__setattr__(key, NestedNamespace(value))\n",
    "            else:\n",
    "                self.__setattr__(key, value)\n",
    "\n",
    "cfg = NestedNamespace(yaml.load(open('../conf/config.yaml'), Loader=Loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bidirected_with_reverse_mapping(g):\n",
    "    \"\"\"Makes a graph bidirectional, and returns a mapping array ``mapping`` where ``mapping[i]``\n",
    "    is the reverse edge of edge ID ``i``. Does not work with graphs that have self-loops.\n",
    "    \"\"\"\n",
    "    g_simple, mapping = dgl.to_simple(\n",
    "        dgl.add_reverse_edges(g), return_counts=\"count\", writeback_mapping=True\n",
    "    )\n",
    "    c = g_simple.edata[\"count\"]\n",
    "    num_edges = g.num_edges()\n",
    "    mapping_offset = torch.zeros(g_simple.num_edges() + 1, dtype=g_simple.idtype)\n",
    "    mapping_offset[1:] = c.cumsum(0)\n",
    "    idx = mapping.argsort()\n",
    "    idx_uniq = idx[mapping_offset[:-1]]\n",
    "    reverse_idx = torch.where(\n",
    "        idx_uniq >= num_edges, idx_uniq - num_edges, idx_uniq + num_edges\n",
    "    )\n",
    "    reverse_mapping = mapping[reverse_idx]\n",
    "    # sanity check\n",
    "    src1, dst1 = g_simple.edges()\n",
    "    src2, dst2 = g_simple.find_edges(reverse_mapping)\n",
    "    assert torch.equal(src1, dst2)\n",
    "    assert torch.equal(src2, dst1)\n",
    "    return g_simple, reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_dataset_root,\n",
    "        data_cpu=False,\n",
    "        fan_out=[10, 25],\n",
    "        device=\"cpu\",\n",
    "        batch_size=1024,\n",
    "        num_workers=4,\n",
    "        force_reload=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        dataset = dgl.data.CSVDataset(csv_dataset_root, force_reload=force_reload)\n",
    "        g = dataset[0]\n",
    "        g, reverse_eids = to_bidirected_with_reverse_mapping(g)\n",
    "        # g = g.formats([\"csc\"])\n",
    "        g = g.to(device)\n",
    "        reverse_eids = reverse_eids.to(device)\n",
    "        # seed_edges = torch.arange(g.num_edges()).to(device)\n",
    "\n",
    "        train_nid = torch.nonzero(g.ndata[\"train_mask\"], as_tuple=True)[0].to(device)\n",
    "        val_nid = torch.nonzero(g.ndata[\"val_mask\"], as_tuple=True)[0].to(device)\n",
    "        test_nid = torch.nonzero(\n",
    "            ~(g.ndata[\"train_mask\"] | g.ndata[\"val_mask\"]), as_tuple=True\n",
    "        )[0].to(device)\n",
    "\n",
    "        sampler = dgl.dataloading.MultiLayerNeighborSampler(\n",
    "            [int(_) for _ in fan_out], prefetch_node_feats=[\"feat\"]\n",
    "        )\n",
    "\n",
    "        self.g = g\n",
    "        self.train_nid, self.val_nid, self.test_nid = train_nid, val_nid, test_nid\n",
    "        self.sampler = sampler\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.in_dim = g.ndata[\"feat\"].shape[1]\n",
    "        self.reverse_eids = reverse_eids\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "            self.sampler,\n",
    "            exclude=\"reverse_id\",\n",
    "            reverse_eids=self.reverse_eids,\n",
    "            negative_sampler=NegativeSampler(self.g, 5)\n",
    "            # negative_sampler=dgl.dataloading.negative_sampler.PerSourceUniform(5),\n",
    "        )\n",
    "\n",
    "        return dgl.dataloading.DataLoader(\n",
    "            self.g,\n",
    "            self.train_nid,\n",
    "            sampler,\n",
    "            device=self.device,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            # num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "            self.sampler,\n",
    "            exclude=\"reverse_id\",\n",
    "            reverse_eids=self.reverse_eids,\n",
    "            negative_sampler=NegativeSampler(self.g, 1)\n",
    "            # negative_sampler=dgl.dataloading.negative_sampler.PerSourceUniform(5),\n",
    "        )\n",
    "\n",
    "        return dgl.dataloading.DataLoader(\n",
    "            self.g,\n",
    "            self.val_nid,\n",
    "            sampler,\n",
    "            device=self.device,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            # num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "# train(cfg)\n",
    "if not torch.cuda.is_available():\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    device = \"cuda\"\n",
    "\n",
    "datamodule = DataModule(cfg.data.zillow_root, device=device, batch_size=cfg.training.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "# Exploring DataModule class\n",
    "csv_dataset_root = cfg.data.zillow_root\n",
    "force_reload=False\n",
    "dataset = dgl.data.CSVDataset(csv_dataset_root, force_reload=force_reload)\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([79966, 79966, 79966,  ..., 57469, 57469, 76505]),\n",
       " tensor([43923, 58296, 32091,  ..., 58296,   873, 69961]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(76505) tensor(69961)\n",
      "tensor(69961) tensor(76505)\n"
     ]
    }
   ],
   "source": [
    "g_reverses = dgl.add_reverse_edges(g)\n",
    "src_rv, dst_rv = g_reverses.edges()\n",
    "\n",
    "num_edges = g.num_edges()\n",
    "print('example original edge:', src_rv[0], dst_rv[0])\n",
    "print('example reverse edge that got added:', src_rv[num_edges], dst_rv[num_edges])\n",
    "\n",
    "g_simple, mapping = dgl.to_simple(g_reverses, return_counts=\"count\", writeback_mapping=True)\n",
    "\n",
    "src_simple, dst_simple = g_simple.edges()\n",
    "print('example original edge after to_simple:', src_simple[num_edges-1], dst_rv[num_edges-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    1,     5,     7,  ..., 84244, 84244, 84244]),\n",
       " tensor([58768, 61026,  9183,  ..., 55507, 61636, 67164]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_simple, mapping = dgl.to_simple(\n",
    "        dgl.add_reverse_edges(g), return_counts=\"count\", writeback_mapping=True\n",
    "    )\n",
    "\n",
    "# dgl.to_simple creates a new set of edge IDs. Whereas previously dgl.add_reverse_edges() just adds a reverse of each edge (thus number of unique edge IDs stays the same),\n",
    "# dgl.to_simple makes each of these new edges created by add_reverse_edges() into their own unique edge, thus doubling the number of unique edge IDs relative to g\n",
    "\n",
    "g_simple.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g_simple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/scratch/alc9635/projects/NYU-Zillow-Capstone-2022-Team-A/notebooks/train_graphsage_explore.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/alc9635/projects/NYU-Zillow-Capstone-2022-Team-A/notebooks/train_graphsage_explore.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m g_simple\u001b[39m.\u001b[39medges()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'g_simple' is not defined"
     ]
    }
   ],
   "source": [
    "g_simple.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 22767,  18275,  85675,  ..., 109849,  62083, 117347])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 22767,  18275,  85675,  ..., 109849,  62083, 117347])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = g_simple.edata['count']\n",
    "mapping_offset = torch.zeros(g_simple.num_edges() + 1, dtype=g_simple.idtype)\n",
    "mapping_offset[1:] = c.cumsum(0)\n",
    "mapping_offset\n",
    "\n",
    "idx = mapping.argsort()\n",
    "idx_uniq = idx[mapping_offset[:-1]]\n",
    "idx_uniq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      1,      2,  ..., 122993, 122994, 122995])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_edges = g.num_edges()\n",
    "reverse_idx = torch.where(idx_uniq >= num_edges, idx_uniq - num_edges, idx_uniq + num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8a98180768ec50653acfbae9679ecd2014a1d8366e4dd2cee9bea05835201d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
